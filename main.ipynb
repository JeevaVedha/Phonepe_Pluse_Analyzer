{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a0ce32",
   "metadata": {},
   "source": [
    "Aggregate insurance data extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated insurance CSV file 'Data_Extract\\Aggregateed_insurance.csv' created successfully with 682 records.\n"
     ]
    }
   ],
   "source": [
    "#Aggregate insurance data extractions\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "path=\"data/aggregated/insurance/country/india/state/\"\n",
    "Agg_state_list=os.listdir(path)\n",
    "#Agg_state_list\n",
    "\n",
    "#print(Agg_state_list)\n",
    "\n",
    "clm={'State':[], 'Year':[],'Quater':[],'Transacion_type':[], 'Transacion_count':[], 'Transacion_amount':[]}\n",
    "\n",
    "output_folder = \"Data_Extract\"\n",
    "\n",
    "for i in Agg_state_list:\n",
    "    p_i=path+i+\"/\"\n",
    "    Agg_yr=os.listdir(p_i)\n",
    "    for j in Agg_yr:\n",
    "        p_j=p_i+j+\"/\"\n",
    "        Agg_yr_list=os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k=p_j+k\n",
    "            Data=open(p_k,'r')\n",
    "            D=json.load(Data)\n",
    "            for z in D['data']['transactionData']:\n",
    "              Name=z['name']\n",
    "              count=z['paymentInstruments'][0]['count']\n",
    "              amount=z['paymentInstruments'][0]['amount']\n",
    "              clm['Transacion_type'].append(Name)\n",
    "              clm['Transacion_count'].append(count)\n",
    "              clm['Transacion_amount'].append(amount)\n",
    "              clm['State'].append(i)\n",
    "              clm['Year'].append(j)\n",
    "              clm['Quater'].append(int(k.strip('.json')))\n",
    "#Succesfully created a dataframe\n",
    "Agg_Trans=pd.DataFrame(clm)\n",
    "\n",
    "# Export to CSV\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_file = os.path.join(output_folder, \"Aggregated_insurance.csv\")\n",
    "Agg_Trans.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "print(f\"Aggregated insurance CSV file '{output_file}' created successfully with {len(Agg_Trans)} records.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d8de00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated transaction CSV file 'Data_Extract\\Aggregated_transaction.csv' created successfully with 5034 records.\n"
     ]
    }
   ],
   "source": [
    "# Aggregate transaction data exratction\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "path=\"data/aggregated/transaction/country/india/state/\"\n",
    "Agg_state_list=os.listdir(path)\n",
    "#Agg_state_list\n",
    "\n",
    "#print(Agg_state_list)\n",
    "\n",
    "clm={'State':[], 'Year':[],'Quater':[],'Transacion_type':[], 'Transacion_count':[], 'Transacion_amount':[]}\n",
    "\n",
    "output_folder = \"Data_Extract\"\n",
    "\n",
    "for i in Agg_state_list:\n",
    "    p_i=path+i+\"/\"\n",
    "    Agg_yr=os.listdir(p_i)\n",
    "    for j in Agg_yr:\n",
    "        p_j=p_i+j+\"/\"\n",
    "        Agg_yr_list=os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k=p_j+k\n",
    "            Data=open(p_k,'r')\n",
    "            D=json.load(Data)\n",
    "            for z in D['data']['transactionData']:\n",
    "              Name=z['name']\n",
    "              count=z['paymentInstruments'][0]['count']\n",
    "              amount=z['paymentInstruments'][0]['amount']\n",
    "              clm['Transacion_type'].append(Name)\n",
    "              clm['Transacion_count'].append(count)\n",
    "              clm['Transacion_amount'].append(amount)\n",
    "              clm['State'].append(i)\n",
    "              clm['Year'].append(j)\n",
    "              clm['Quater'].append(int(k.strip('.json')))\n",
    "#Succesfully created a dataframe\n",
    "Agg_Trans=pd.DataFrame(clm)\n",
    "\n",
    "# Export to CSV\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_file = os.path.join(output_folder, \"Aggregated_transaction.csv\")\n",
    "Agg_Trans.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Aggregated transaction CSV file '{output_file}' created successfully with {len(Agg_Trans)} records.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c2d81441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated user CSV file 'Data_Extract\\Aggregated_user.csv' created successfully with 6732 records.\n"
     ]
    }
   ],
   "source": [
    "# Aggregate User data exratction\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "path=\"data/aggregated/user/country/india/state/\"\n",
    "Agg_state_list=os.listdir(path)\n",
    "#Agg_state_list\n",
    "\n",
    "#print(Agg_state_list)\n",
    "\n",
    "clm={'State':[], 'Year':[],'Quater':[],'Brand':[], 'Transaction_count':[], 'Transaction_percentage':[]}\n",
    "\n",
    "output_folder = \"Data_Extract\"\n",
    "\n",
    "for i in Agg_state_list:\n",
    "    p_i=path+i+\"/\"\n",
    "    Agg_yr=os.listdir(p_i)\n",
    "    for j in Agg_yr:\n",
    "        p_j=p_i+j+\"/\"\n",
    "        Agg_yr_list=os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k=p_j+k\n",
    "            Data=open(p_k,'r')\n",
    "            D=json.load(Data)\n",
    "            if D['data']['usersByDevice']:\n",
    "                    for z in D['data']['usersByDevice']:\n",
    "                        brand = z['brand']\n",
    "                        count = z['count']\n",
    "                        percentage = z['percentage']\n",
    "                        \n",
    "                        clm['State'].append(i)\n",
    "                        clm['Year'].append(j)\n",
    "                        clm['Quater'].append(int(k.strip('.json')))\n",
    "                        clm['Brand'].append(brand)\n",
    "                        clm['Transaction_count'].append(count)\n",
    "                        clm['Transaction_percentage'].append(percentage)\n",
    "#Succesfully created a dataframe\n",
    "Agg_Trans=pd.DataFrame(clm)\n",
    "\n",
    "# Export to CSV\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_file = os.path.join(output_folder, \"Aggregated_user.csv\")\n",
    "Agg_Trans.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Aggregated user CSV file '{output_file}' created successfully with {len(Agg_Trans)} records.\") \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9203aa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map insurance CSV file 'Data_Extract\\Map_insurance.csv' created successfully with 13876 records.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory path\n",
    "path = \"data/map/insurance/hover/country/india/state/\"\n",
    "Agg_state_list = os.listdir(path)\n",
    "\n",
    "# Initialize the dataframe columns\n",
    "clm = {'State': [],'Year': [],'Quarter': [],'District': [],'Transaction_count': [],'Transaction_amount': []}\n",
    "\n",
    "output_folder = \"Data_Extract\"\n",
    "\n",
    "# Loop through each state\n",
    "for i in Agg_state_list:\n",
    "    p_i=path+i+\"/\"\n",
    "    Agg_yr=os.listdir(p_i) \n",
    "    for j in Agg_yr:\n",
    "        p_j=p_i+j+\"/\"\n",
    "        Agg_yr_list=os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k=p_j+k\n",
    "            Data=open(p_k,'r')\n",
    "            D=json.load(Data)\n",
    "            hover_list = D.get('data', {}).get('hoverDataList', [])\n",
    "            for z in hover_list:\n",
    "                name = z.get('name')\n",
    "                metric = next((m for m in z.get('metric', []) if m.get('type') == 'TOTAL'), None)\n",
    "                if metric:\n",
    "                        count = metric.get('count')\n",
    "                        amount = metric.get('amount')\n",
    "                        clm['State'].append(i)\n",
    "                        clm['Year'].append(j)\n",
    "                        clm['Quarter'].append(int(k.strip('.json')))\n",
    "                        clm['District'].append(name)\n",
    "                        clm['Transaction_count'].append(count)\n",
    "                        clm['Transaction_amount'].append(amount)\n",
    "\n",
    "Agg_Trans=pd.DataFrame(clm)\n",
    "\n",
    "# Export to CSV\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_file = os.path.join(output_folder, \"Map_insurance.csv\")\n",
    "Agg_Trans.to_csv(output_file, index=False)\n",
    "              \n",
    "print(f\"Map insurance CSV file '{output_file}' created successfully with {len(Agg_Trans)} records.\")   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d38d952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map transaction CSV file 'Data_Extract\\Map_transaction.csv' created successfully with 20604 records.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory path\n",
    "path = \"data/map/transaction/hover/country/india/state/\"\n",
    "Agg_state_list = os.listdir(path)\n",
    "\n",
    "# Initialize the dataframe columns\n",
    "clm = {'State': [],'Year': [],'Quarter': [],'District': [],'Transaction_count': [],'Transaction_amount': []}\n",
    "\n",
    "output_folder = \"Data_Extract\"\n",
    "\n",
    "# Loop through each state\n",
    "for i in Agg_state_list:\n",
    "    p_i=path+i+\"/\"\n",
    "    Agg_yr=os.listdir(p_i) \n",
    "    for j in Agg_yr:\n",
    "        p_j=p_i+j+\"/\"\n",
    "        Agg_yr_list=os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k=p_j+k\n",
    "            Data=open(p_k,'r')\n",
    "            D=json.load(Data)\n",
    "            hover_list = D.get('data', {}).get('hoverDataList', [])\n",
    "            for z in hover_list:\n",
    "                name = z.get('name')\n",
    "                metric = next((m for m in z.get('metric', []) if m.get('type') == 'TOTAL'), None)\n",
    "                if metric:\n",
    "                        count = metric.get('count')\n",
    "                        amount = metric.get('amount')\n",
    "                        clm['State'].append(i)\n",
    "                        clm['Year'].append(j)\n",
    "                        clm['Quarter'].append(int(k.strip('.json')))\n",
    "                        clm['District'].append(name)\n",
    "                        clm['Transaction_count'].append(count)\n",
    "                        clm['Transaction_amount'].append(amount)\n",
    "\n",
    "Agg_Trans=pd.DataFrame(clm)\n",
    "\n",
    "# Export to CSV\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_file = os.path.join(output_folder, \"Map_transaction.csv\")\n",
    "Agg_Trans.to_csv(output_file, index=False)\n",
    "   \n",
    "print(f\"Map transaction CSV file '{output_file}' created successfully with {len(Agg_Trans)} records.\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8d60600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map user CSV file 'Data_Extract\\Map_user.csv' created successfully with 20608 records.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory path\n",
    "path = \"data/map/user/hover/country/india/state/\"\n",
    "Agg_state_list = os.listdir(path)\n",
    "\n",
    "# Initialize the dataframe columns\n",
    "clm = {'State': [], 'Year': [], 'Quarter': [], 'District': [], 'Registered_Users': [], 'App_Opens': []}\n",
    "\n",
    "output_folder = \"Data_Extract\"\n",
    "# Loop through each state\n",
    "for i in Agg_state_list:\n",
    "    p_i = path + i + \"/\"\n",
    "    Agg_yr = os.listdir(p_i)\n",
    "    for j in Agg_yr:\n",
    "        p_j = p_i + j + \"/\"\n",
    "        Agg_yr_list = os.listdir(p_j)\n",
    "        for k in Agg_yr_list:\n",
    "            p_k = p_j + k\n",
    "            with open(p_k, 'r') as Data:\n",
    "                D = json.load(Data)\n",
    "                hover_data = D.get('data', {}).get('hoverData', {})\n",
    "                for district, stats in hover_data.items():\n",
    "                    registered_users = stats.get('registeredUsers')\n",
    "                    app_opens = stats.get('appOpens')\n",
    "                    clm['State'].append(i)\n",
    "                    clm['Year'].append(j)\n",
    "                    clm['Quarter'].append(int(k.strip('.json')))\n",
    "                    clm['District'].append(district)\n",
    "                    clm['Registered_Users'].append(registered_users)\n",
    "                    clm['App_Opens'].append(app_opens)\n",
    "\n",
    "# Create DataFrame\n",
    "Agg_Trans = pd.DataFrame(clm)\n",
    "\n",
    "# Export to CSV\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_file = os.path.join(output_folder, \"Map_user.csv\")\n",
    "Agg_Trans.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Map user CSV file '{output_file}' created successfully with {len(Agg_Trans)} records.\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "502905d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top transaction CSV file 'Data_Extract\\Top_transaction.csv' created successfully with 18295 records.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory path for TOP data\n",
    "path = \"data/top/transaction/country/india/state/\"\n",
    "Agg_state_list = os.listdir(path)\n",
    "\n",
    "# Initialize combined data dictionary\n",
    "combined_data = {\n",
    "    'State': [],        # folder-level state (from file organization)\n",
    "    'Year': [],         # year folder\n",
    "    'Quarter': [],      # quarter from filename\n",
    "    'Level': [],        # 'State' / 'District' / 'Pincode'\n",
    "    'Entity_Name': [],  # actual entity name (state, district, or pincode)\n",
    "    'Transaction_Count': [],\n",
    "    'Transaction_Amount': []\n",
    "}\n",
    "\n",
    "# Counter for skipped files\n",
    "skipped_files = []\n",
    "\n",
    "output_folder = \"Data_Extract\"\n",
    "\n",
    "# Loop over each state folder\n",
    "for i in Agg_state_list:\n",
    "    p_i = os.path.join(path, i)\n",
    "    Agg_yr = os.listdir(p_i)\n",
    "\n",
    "    for j in Agg_yr:\n",
    "        p_j = os.path.join(p_i, j)\n",
    "        Agg_yr_list = os.listdir(p_j)\n",
    "\n",
    "        for k in Agg_yr_list:\n",
    "            p_k = os.path.join(p_j, k)\n",
    "\n",
    "            try:\n",
    "                with open(p_k, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    quarter = int(k.strip('.json'))\n",
    "                    data_section = data.get('data', {})\n",
    "\n",
    "                    # Process states (if present)\n",
    "                    state_list = data_section.get('states')\n",
    "                    if isinstance(state_list, list):\n",
    "                        for s in state_list:\n",
    "                            combined_data['State'].append(i)\n",
    "                            combined_data['Year'].append(j)\n",
    "                            combined_data['Quarter'].append(quarter)\n",
    "                            combined_data['Level'].append('State')\n",
    "                            combined_data['Entity_Name'].append(s.get('entityName'))\n",
    "                            combined_data['Transaction_Count'].append(s.get('metric', {}).get('count'))\n",
    "                            combined_data['Transaction_Amount'].append(s.get('metric', {}).get('amount'))\n",
    "\n",
    "                    # Process districts (if present)\n",
    "                    district_list = data_section.get('districts')\n",
    "                    if isinstance(district_list, list):\n",
    "                        for d in district_list:\n",
    "                            combined_data['State'].append(i)\n",
    "                            combined_data['Year'].append(j)\n",
    "                            combined_data['Quarter'].append(quarter)\n",
    "                            combined_data['Level'].append('District')\n",
    "                            combined_data['Entity_Name'].append(d.get('entityName'))\n",
    "                            combined_data['Transaction_Count'].append(d.get('metric', {}).get('count'))\n",
    "                            combined_data['Transaction_Amount'].append(d.get('metric', {}).get('amount'))\n",
    "\n",
    "                    # Process pincodes (if present)\n",
    "                    pincode_list = data_section.get('pincodes')\n",
    "                    if isinstance(pincode_list, list):\n",
    "                        for p in pincode_list:\n",
    "                            combined_data['State'].append(i)\n",
    "                            combined_data['Year'].append(j)\n",
    "                            combined_data['Quarter'].append(quarter)\n",
    "                            combined_data['Level'].append('Pincode')\n",
    "                            combined_data['Entity_Name'].append(p.get('entityName'))\n",
    "                            combined_data['Transaction_Count'].append(p.get('metric', {}).get('count'))\n",
    "                            combined_data['Transaction_Amount'].append(p.get('metric', {}).get('amount'))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipped file: {k} due to error: {e}\")\n",
    "                skipped_files.append(k)\n",
    "\n",
    "# Create DataFrame\n",
    "df_combined = pd.DataFrame(combined_data)\n",
    "\n",
    "# Export to CSV\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_file = os.path.join(output_folder, \"Top_transaction.csv\")\n",
    "df_combined.to_csv(output_file, index=False)\n",
    "\n",
    " \n",
    "\n",
    "print(f\"Top transaction CSV file '{output_file}' created successfully with {len(df_combined)} records.\")\n",
    "\n",
    "if skipped_files:\n",
    "    print(f\"\\nSkipped {len(skipped_files)} files due to errors. List:\")\n",
    "    for file in skipped_files:\n",
    "        print(f\"- {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b1ef36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV file 'Data_Extract\\Top_insurance.csv' created successfully with 12276 records.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory path for TOP data\n",
    "path = \"data/top/insurance/country/india/state/\"\n",
    "Agg_state_list = os.listdir(path)\n",
    "\n",
    "# Initialize combined data dictionary\n",
    "combined_data = {\n",
    "    'State': [],        # folder-level state (from file organization)\n",
    "    'Year': [],         # year folder\n",
    "    'Quarter': [],      # quarter from filename\n",
    "    'Level': [],        # 'State' / 'District' / 'Pincode'\n",
    "    'Entity_Name': [],  # actual entity name (state, district, or pincode)\n",
    "    'Transaction_Count': [],\n",
    "    'Transaction_Amount': []\n",
    "}\n",
    "\n",
    "# Counter for skipped files\n",
    "skipped_files = []\n",
    "\n",
    "output_folder = \"Data_Extract\"\n",
    "\n",
    "# Loop over each state folder\n",
    "for i in Agg_state_list:\n",
    "    p_i = os.path.join(path, i)\n",
    "    Agg_yr = os.listdir(p_i)\n",
    "\n",
    "    for j in Agg_yr:\n",
    "        p_j = os.path.join(p_i, j)\n",
    "        Agg_yr_list = os.listdir(p_j)\n",
    "\n",
    "        for k in Agg_yr_list:\n",
    "            p_k = os.path.join(p_j, k)\n",
    "\n",
    "            try:\n",
    "                with open(p_k, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    quarter = int(k.strip('.json'))\n",
    "                    data_section = data.get('data', {})\n",
    "\n",
    "                    # Process states (if present)\n",
    "                    state_list = data_section.get('states')\n",
    "                    if isinstance(state_list, list):\n",
    "                        for s in state_list:\n",
    "                            combined_data['State'].append(i)\n",
    "                            combined_data['Year'].append(j)\n",
    "                            combined_data['Quarter'].append(quarter)\n",
    "                            combined_data['Level'].append('State')\n",
    "                            combined_data['Entity_Name'].append(s.get('entityName'))\n",
    "                            combined_data['Transaction_Count'].append(s.get('metric', {}).get('count'))\n",
    "                            combined_data['Transaction_Amount'].append(s.get('metric', {}).get('amount'))\n",
    "\n",
    "                    # Process districts (if present)\n",
    "                    district_list = data_section.get('districts')\n",
    "                    if isinstance(district_list, list):\n",
    "                        for d in district_list:\n",
    "                            combined_data['State'].append(i)\n",
    "                            combined_data['Year'].append(j)\n",
    "                            combined_data['Quarter'].append(quarter)\n",
    "                            combined_data['Level'].append('District')\n",
    "                            combined_data['Entity_Name'].append(d.get('entityName'))\n",
    "                            combined_data['Transaction_Count'].append(d.get('metric', {}).get('count'))\n",
    "                            combined_data['Transaction_Amount'].append(d.get('metric', {}).get('amount'))\n",
    "\n",
    "                    # Process pincodes (if present)\n",
    "                    pincode_list = data_section.get('pincodes')\n",
    "                    if isinstance(pincode_list, list):\n",
    "                        for p in pincode_list:\n",
    "                            combined_data['State'].append(i)\n",
    "                            combined_data['Year'].append(j)\n",
    "                            combined_data['Quarter'].append(quarter)\n",
    "                            combined_data['Level'].append('Pincode')\n",
    "                            combined_data['Entity_Name'].append(p.get('entityName'))\n",
    "                            combined_data['Transaction_Count'].append(p.get('metric', {}).get('count'))\n",
    "                            combined_data['Transaction_Amount'].append(p.get('metric', {}).get('amount'))\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipped file: {k} due to error: {e}\")\n",
    "                skipped_files.append(k)\n",
    "\n",
    "# Create DataFrame\n",
    "df_combined = pd.DataFrame(combined_data)\n",
    "\n",
    "# Export to CSV\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_file = os.path.join(output_folder, \"Top_insurance.csv\")\n",
    "df_combined.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "print(f\"Top insurance CSV file '{output_file}' created successfully with {len(df_combined)} records.\")\n",
    "\n",
    "if skipped_files:\n",
    "    print(f\"\\nSkipped {len(skipped_files)} files due to errors. List:\")\n",
    "    for file in skipped_files:\n",
    "        print(f\"- {file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01b73049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top user CSV file 'Data_Extract\\Top_user.csv' created successfully with 18296 records.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Base directory path for TOP data\n",
    "path = \"data/top/user/country/india/state/\"\n",
    "Agg_state_list = os.listdir(path)\n",
    "\n",
    "# Initialize combined data dictionary\n",
    "combined_data = {\n",
    "    'State': [],        # folder-level state (from file organization)\n",
    "    'Year': [],         # year folder\n",
    "    'Quarter': [],      # quarter from filename\n",
    "    'Level': [],        # 'State' / 'District' / 'Pincode'\n",
    "     \n",
    "}\n",
    "\n",
    "# Counter for skipped files\n",
    "skipped_files = []\n",
    "\n",
    "output_folder = \"Data_Extract\"\n",
    "\n",
    "\n",
    "# Loop over each state folder\n",
    "for i in Agg_state_list:\n",
    "    p_i = os.path.join(path, i)\n",
    "    Agg_yr = os.listdir(p_i)\n",
    "\n",
    "    for j in Agg_yr:\n",
    "        p_j = os.path.join(p_i, j)\n",
    "        Agg_yr_list = os.listdir(p_j)\n",
    "\n",
    "        for k in Agg_yr_list:\n",
    "            p_k = os.path.join(p_j, k)\n",
    "\n",
    "            try:\n",
    "                with open(p_k, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    quarter = int(k.strip('.json'))\n",
    "                    data_section = data.get('data', {})\n",
    "\n",
    "                    # Process states (if present)\n",
    "                    state_list = data_section.get('states')\n",
    "                    if isinstance(state_list, list):\n",
    "                        for s in state_list:\n",
    "                            combined_data['State'].append(i)\n",
    "                            combined_data['Year'].append(j)\n",
    "                            combined_data['Quarter'].append(quarter)\n",
    "                            combined_data['Level'].append('State')\n",
    "                             \n",
    "\n",
    "                    # Process districts (if present)\n",
    "                    district_list = data_section.get('districts')\n",
    "                    if isinstance(district_list, list):\n",
    "                        for d in district_list:\n",
    "                            combined_data['State'].append(i)\n",
    "                            combined_data['Year'].append(j)\n",
    "                            combined_data['Quarter'].append(quarter)\n",
    "                            combined_data['Level'].append('District')\n",
    "                            \n",
    "\n",
    "                    # Process pincodes (if present)\n",
    "                    pincode_list = data_section.get('pincodes')\n",
    "                    if isinstance(pincode_list, list):\n",
    "                        for p in pincode_list:\n",
    "                            combined_data['State'].append(i)\n",
    "                            combined_data['Year'].append(j)\n",
    "                            combined_data['Quarter'].append(quarter)\n",
    "                            combined_data['Level'].append('Pincode')\n",
    "                             \n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Skipped file: {k} due to error: {e}\")\n",
    "                skipped_files.append(k)\n",
    "\n",
    "# Create DataFrame\n",
    "df_combined = pd.DataFrame(combined_data)\n",
    "\n",
    "# Export to CSV\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_file = os.path.join(output_folder, \"Top_user.csv\")\n",
    "df_combined.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Top user CSV file '{output_file}' created successfully with {len(df_combined)} records.\")\n",
    "\n",
    "if skipped_files:\n",
    "    print(f\"\\nSkipped {len(skipped_files)} files due to errors. List:\")\n",
    "    for file in skipped_files:\n",
    "        print(f\"- {file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
